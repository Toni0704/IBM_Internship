# IBM_Internship

## Rag Implementation

The file rag_ollama.py consists of RAG implementation using "llama3.1" model run locally using Ollama.

Reference: https://dev.to/dmuraco3/how-to-create-a-local-rag-agent-with-ollama-and-langchain-1m9a

## My first AI Agent

Used "llama3.1" model along with langchain to create an AI agent that uses some basic python defined functions as tools. 

The response of the agent is not yet optimal. I have noticed some merit in tuning the prompt template to improve the output. Work in Progress... Please let me know if there are any suggestions.

Reference: https://github.com/IBM/watsonx-ai-samples/blob/master/cloud/notebooks/python_sdk/deployments/foundation_models/Use%20watsonx%2C%20and%20LangChain%20Agents%20to%20perform%20sequence%20of%20actions.ipynb
