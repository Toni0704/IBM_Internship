{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosting llama model using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434/api/generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"incomprehensibility\" has 17 letters: i-n-c-o-m-p-r-e-h-e-n-s-i-b-i-l-i-t-y.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "class OllamaLLM:\n",
    "    def __init__(self, model_name, url=\"http://localhost:11434/api/generate\", params=None):\n",
    "        \"\"\"\n",
    "        Initialize Ollama LLM with a specific model and API endpoint.\n",
    "        \n",
    "        Parameters:\n",
    "        - model_name (str): Name of the Ollama model (e.g., \"llama3.1\", \"mistral\").\n",
    "        - url (str): URL for the Ollama server (default is localhost).\n",
    "        - params (dict): Additional parameters for the model (optional).\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.model_name = model_name\n",
    "        self.params = params or {}\n",
    "\n",
    "    def generate(self, prompt, stream=False):\n",
    "        \"\"\"\n",
    "        Generate a response from the LLM.\n",
    "\n",
    "        Parameters:\n",
    "        - prompt (str): Input prompt to send to the model.\n",
    "        - stream (bool): Enable streaming (default: False).\n",
    "\n",
    "        Returns:\n",
    "        - str: The generated response.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": stream,\n",
    "        }\n",
    "        data.update(self.params)\n",
    "\n",
    "        # Send a POST request to Ollama API\n",
    "        response = requests.post(self.url, json=data)\n",
    "\n",
    "        # Check for errors\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['response']\n",
    "        else:\n",
    "            raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    def bind(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Bind additional parameters to the model.\n",
    "\n",
    "        Parameters:\n",
    "        - kwargs: Key-value pairs of additional model parameters.\n",
    "\n",
    "        Returns:\n",
    "        - OllamaLLM: A new instance with updated parameters.\n",
    "        \"\"\"\n",
    "        # Create a new instance with updated parameters\n",
    "        new_params = self.params.copy()\n",
    "        new_params.update(kwargs)\n",
    "        return OllamaLLM(model_name=self.model_name, url=self.url, params=new_params)\n",
    "    \n",
    "\n",
    "llm_chat = OllamaLLM(\n",
    "    model_name=\"llama3.1\",  \n",
    "    params={\"temperature\": 0.7, \"top_p\": 0.9} \n",
    ")\n",
    "\n",
    "# Example usage\n",
    "response = llm_chat.generate(\"What is the length of the word 'incomprehensibility'\")  # Calling with a prompt\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template prep and tools (Not being used right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Below are a series of dialogues between various people and an AI assistant. The AI tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant prioritizes caution over usefulness, refusing to answer questions that it considers unsafe, immoral, unethical or dangerous. \n",
    "\n",
    "AI assistant has access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a JSON blob to specify a tool by providing an action key (tool name) and an action input key (tool input). \n",
    "\n",
    "Use only valid \"action\" values: \"Final Answer\" or {tool_names} and provide only one action per $JSON_BLOB. Use \"action\" value \"Final Answer\" if you know what to respond. Provide only ONE action per $JSON_BLOB, as shown:\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "Follow this format:\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "\n",
    "Reminder to ALWAYS respond with a valid JSON blob of a single action. Use tools only if necessary. Format is Action:```$JSON_BLOB```then Observation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '{input}\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what and use tools only if necessary)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create structured prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", system_prompt\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        (\"user\", user_input),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Below are a series of dialogues between various people and an AI assistant. The AI tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant prioritizes caution over usefulness, refusing to answer questions that it considers unsafe, immoral, unethical or dangerous. \\n\\nAI assistant has access to the following tools:\\n\\n{tools}\\n\\nUse a JSON blob to specify a tool by providing an action key (tool name) and an action input key (tool input). \\n\\nUse only valid \"action\" values: \"Final Answer\" or {tool_names} and provide only one action per $JSON_BLOB. Use \"action\" value \"Final Answer\" if you know what to respond. Provide only ONE action per $JSON_BLOB, as shown:\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\nFollow this format:\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nReminder to ALWAYS respond with a valid JSON blob of a single action. Use tools only if necessary. Format is Action:```$JSON_BLOB```then Observation\\n'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what and use tools only if necessary)'), additional_kwargs={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Return the length of the given word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "@tool\n",
    "def remove_punctuations(text: str) -> str:\n",
    "    \"\"\"Remove all punctuation symbols from the text.\"\"\"\n",
    "    new_string = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return new_string\n",
    "\n",
    "@tool\n",
    "def get_mean_from_sequence(sequence: str) -> float:\n",
    "    \"\"\"Return the mean value from the sequence of numbers.\"\"\"\n",
    "    return float(np.mean(np.array(sequence.split(','), dtype=float)))\n",
    "\n",
    "# Structured tools\n",
    "def get_normalize_vector(vector: list[float]) -> str:\n",
    "    \"\"\"Return a normalized `vector`.\"\"\"\n",
    "    return str(list(vector / np.sqrt(np.sum(np.array(vector)**2))))\n",
    "\n",
    "get_normalize_vector_structured = StructuredTool.from_function(\n",
    "    func=get_normalize_vector,\n",
    "    name=\"get_normalize_vector\",\n",
    "    description=\"Useful when you want to normalize a vector. Input should be a list of float numbers.\",\n",
    ")\n",
    "\n",
    "def get_gcd(a: int, b: int) -> int:\n",
    "    \"\"\"Return the greatest common divisor of the two integers.\"\"\"\n",
    "    return math.gcd(a, b)\n",
    "\n",
    "get_gcd_structured = StructuredTool.from_function(\n",
    "    func=get_gcd,\n",
    "    name=\"get_gcd\",\n",
    "    description=\"Useful when you want to find greatest common divisor of the two integers.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/0x9ylhq57vq55_ssc_tyqhc00000gn/T/ipykernel_6035/1217889429.py:93: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Query: What is the length of the word 'incomprehensibility'?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Thought: I need to find out the length of the word\n",
      "Action: get_word_length\n",
      "Action Input: incomprehensibility\u001b[32;1m\u001b[1;3mThought: I need to find out the length of the word\n",
      "Action: get_word_length\n",
      "Action Input: incomprehensibility\u001b[0m\u001b[36;1m\u001b[1;3m19\u001b[0mThought: I've seen the result\n",
      "Action: None (since we already have the answer)\n",
      "Final Answer: The length of the word 'incomprehensibility' is 19.\u001b[32;1m\u001b[1;3mThought: I've seen the result\n",
      "Action: None (since we already have the answer)\n",
      "Final Answer: The length of the word 'incomprehensibility' is 19.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tools Available: ['get_word_length', 'get_mean_from_sequence', 'remove_punctuations', 'get_normalize_vector', 'get_gcd']\n",
      "\n",
      "Raw result: {'input': \"What is the length of the word 'incomprehensibility'?\", 'chat_history': [], 'output': \"The length of the word 'incomprehensibility' is 19.\", 'intermediate_steps': [(AgentAction(tool='get_word_length', tool_input='incomprehensibility', log='Thought: I need to find out the length of the word\\nAction: get_word_length\\nAction Input: incomprehensibility'), 19)]}\n",
      "Final Response: \n",
      "ðŸ›  **Tool Used:** get_word_length\n",
      "   ðŸ”¹ **Input:** incomprehensibility\n",
      "   ðŸ”¹ **Output:** 19\n",
      "\n",
      "\n",
      "**Final Answer:** The length of the word 'incomprehensibility' is 19.\n",
      "\n",
      "\n",
      "Query: What is the mean of these numbers: 10,15,20,25,30?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Thought: I need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None (since we already have the answer)\n",
      "\n",
      "However, since I need to follow the format exactly as shown above, I'll add an empty action for clarity.\n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: Thought: I need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None (since we already have the answer)\n",
      "\n",
      "However, since I need to follow the format exactly as shown above, I'll add an empty action for clarity.\n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete responseI need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None \n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: I need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None \n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete responseThought: I need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None \n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: Thought: I need to find out the mean value from the sequence of numbers.\n",
      "Action: get_mean_from_sequence\n",
      "Action Input: 10,15,20,25,30\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a result\n",
      "Action: None \n",
      "\n",
      " Thought: I know the answer\n",
      "Final Answer: The final answer is $\\boxed{20.0}$.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tools Available: ['get_word_length', 'get_mean_from_sequence', 'remove_punctuations', 'get_normalize_vector', 'get_gcd']\n",
      "\n",
      "Raw result: {'input': 'What is the mean of these numbers: 10,15,20,25,30?', 'chat_history': [HumanMessage(content=\"What is the length of the word 'incomprehensibility'?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\nðŸ›  **Tool Used:** get_word_length\\n   ðŸ”¹ **Input:** incomprehensibility\\n   ðŸ”¹ **Output:** 19\\n\\n\\n**Final Answer:** The length of the word 'incomprehensibility' is 19.\", additional_kwargs={}, response_metadata={})], 'output': 'Agent stopped due to iteration limit or time limit.', 'intermediate_steps': [(AgentAction(tool='_Exception', tool_input='Invalid or incomplete response', log=\"Parsing LLM output produced both a final answer and a parse-able action:: Thought: I need to find out the mean value from the sequence of numbers.\\nAction: get_mean_from_sequence\\nAction Input: 10,15,20,25,30\\n\\nI've seen the result\\nThought: The tool has given me a result\\nAction: None (since we already have the answer)\\n\\nHowever, since I need to follow the format exactly as shown above, I'll add an empty action for clarity.\\n\\n Thought: I know the answer\\nFinal Answer: The final answer is $\\\\boxed{20.0}$.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \"), 'Invalid or incomplete response'), (AgentAction(tool='_Exception', tool_input='Invalid or incomplete response', log=\"Parsing LLM output produced both a final answer and a parse-able action:: I need to find out the mean value from the sequence of numbers.\\nAction: get_mean_from_sequence\\nAction Input: 10,15,20,25,30\\n\\nI've seen the result\\nThought: The tool has given me a result\\nAction: None \\n\\n Thought: I know the answer\\nFinal Answer: The final answer is $\\\\boxed{20.0}$.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \"), 'Invalid or incomplete response'), (AgentAction(tool='_Exception', tool_input='Invalid or incomplete response', log=\"Parsing LLM output produced both a final answer and a parse-able action:: Thought: I need to find out the mean value from the sequence of numbers.\\nAction: get_mean_from_sequence\\nAction Input: 10,15,20,25,30\\n\\nI've seen the result\\nThought: The tool has given me a result\\nAction: None \\n\\n Thought: I know the answer\\nFinal Answer: The final answer is $\\\\boxed{20.0}$.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \"), 'Invalid or incomplete response')]}\n",
      "Final Response: \n",
      "ðŸ›  **Tool Used:** _Exception\n",
      "   ðŸ”¹ **Input:** Invalid or incomplete response\n",
      "   ðŸ”¹ **Output:** Invalid or incomplete response\n",
      "\n",
      "ðŸ›  **Tool Used:** _Exception\n",
      "   ðŸ”¹ **Input:** Invalid or incomplete response\n",
      "   ðŸ”¹ **Output:** Invalid or incomplete response\n",
      "\n",
      "ðŸ›  **Tool Used:** _Exception\n",
      "   ðŸ”¹ **Input:** Invalid or incomplete response\n",
      "   ðŸ”¹ **Output:** Invalid or incomplete response\n",
      "\n",
      "\n",
      "**Final Answer:** Agent stopped due to iteration limit or time limit.\n",
      "\n",
      "\n",
      "Query: What is the GCD of 48 and 18?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Thought: I need to find out the GCD of two numbers\n",
      "Action: get_gcd\n",
      "Action Input: a = 48, b = 18\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the GCD of two numbers\n",
      "Action: get_gcd\n",
      "Action Input: a = 48, b = 18\n",
      "\u001b[0mError executing agent: 2 validation errors for get_gcd\n",
      "a\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a = 48, b = 18\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\n",
      "b\n",
      "  Field required [type=missing, input_value={'a': 'a = 48, b = 18\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Final Response: Error executing agent: 2 validation errors for get_gcd\n",
      "a\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a = 48, b = 18\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\n",
      "b\n",
      "  Field required [type=missing, input_value={'a': 'a = 48, b = 18\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "\n",
      "\n",
      "Query: Can you normalize this vector: [3, 4]?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Thought: I need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a normalized vector\n",
      "Final Answer: $\\boxed{[0.6, 0.8]}$\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: Thought: I need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a normalized vector\n",
      "Final Answer: $\\boxed{[0.6, 0.8]}$\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete responseIt seems like there was an issue with parsing the LLM output.\n",
      "\n",
      "Let's try again from scratch:\n",
      "\n",
      "Thought: I need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "Please wait for the result... \n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a normalized vector\n",
      "Final Answer: $\\boxed{[0.6, 0.8]}$\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: It seems like there was an issue with parsing the LLM output.\n",
      "\n",
      "Let's try again from scratch:\n",
      "\n",
      "Thought: I need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "Please wait for the result... \n",
      "\n",
      "I've seen the result\n",
      "Thought: The tool has given me a normalized vector\n",
      "Final Answer: $\\boxed{[0.6, 0.8]}$\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete responseI need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "I've seen the result\n",
      "The normalized vector is [0.6, 0.8]\u001b[32;1m\u001b[1;3mI need to find out something\n",
      "Action: get_normalize_vector\n",
      "Action Input: [3, 4]\n",
      "\n",
      "I've seen the result\n",
      "The normalized vector is [0.6, 0.8]\u001b[0mError executing agent: 1 validation error for get_normalize_vector\n",
      "vector\n",
      "  Input should be a valid list [type=list_type, input_value=\"[3, 4]\\n\\nI've seen the ...ed vector is [0.6, 0.8]\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/list_type\n",
      "Final Response: Error executing agent: 1 validation error for get_normalize_vector\n",
      "vector\n",
      "  Input should be a valid list [type=list_type, input_value=\"[3, 4]\\n\\nI've seen the ...ed vector is [0.6, 0.8]\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/list_type\n",
      "\n",
      "\n",
      "Query: Remove the punctuation from this sentence: Hello, world! How are you doing today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Thought: I need to remove the punctuation from the given text\n",
      "Action: remove_punctuations\n",
      "Action Input: Hello, world! How are you doing today?\u001b[32;1m\u001b[1;3mThought: I need to remove the punctuation from the given text\n",
      "Action: remove_punctuations\n",
      "Action Input: Hello, world! How are you doing today?\u001b[0m\u001b[38;5;200m\u001b[1;3mHello world How are you doing today\u001b[0mThought: I've seen the result\n",
      "Action: get_word_length\n",
      "Action Input: Hello world How are you doing today?\u001b[32;1m\u001b[1;3mThought: I've seen the result\n",
      "Action: get_word_length\n",
      "Action Input: Hello world How are you doing today?\u001b[0m\u001b[36;1m\u001b[1;3m36\u001b[0mThought: I know the answer\n",
      "Final Answer: The length of the text after removing punctuation is 36.\u001b[32;1m\u001b[1;3mThought: I know the answer\n",
      "Final Answer: The length of the text after removing punctuation is 36.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tools Available: ['get_word_length', 'get_mean_from_sequence', 'remove_punctuations', 'get_normalize_vector', 'get_gcd']\n",
      "\n",
      "Raw result: {'input': 'Remove the punctuation from this sentence: Hello, world! How are you doing today?', 'chat_history': [HumanMessage(content=\"What is the length of the word 'incomprehensibility'?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\nðŸ›  **Tool Used:** get_word_length\\n   ðŸ”¹ **Input:** incomprehensibility\\n   ðŸ”¹ **Output:** 19\\n\\n\\n**Final Answer:** The length of the word 'incomprehensibility' is 19.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the mean of these numbers: 10,15,20,25,30?', additional_kwargs={}, response_metadata={}), AIMessage(content='\\nðŸ›  **Tool Used:** _Exception\\n   ðŸ”¹ **Input:** Invalid or incomplete response\\n   ðŸ”¹ **Output:** Invalid or incomplete response\\n\\nðŸ›  **Tool Used:** _Exception\\n   ðŸ”¹ **Input:** Invalid or incomplete response\\n   ðŸ”¹ **Output:** Invalid or incomplete response\\n\\nðŸ›  **Tool Used:** _Exception\\n   ðŸ”¹ **Input:** Invalid or incomplete response\\n   ðŸ”¹ **Output:** Invalid or incomplete response\\n\\n\\n**Final Answer:** Agent stopped due to iteration limit or time limit.', additional_kwargs={}, response_metadata={})], 'output': 'The length of the text after removing punctuation is 36.', 'intermediate_steps': [(AgentAction(tool='remove_punctuations', tool_input='Hello, world! How are you doing today?', log='Thought: I need to remove the punctuation from the given text\\nAction: remove_punctuations\\nAction Input: Hello, world! How are you doing today?'), 'Hello world How are you doing today'), (AgentAction(tool='get_word_length', tool_input='Hello world How are you doing today?', log=\"Thought: I've seen the result\\nAction: get_word_length\\nAction Input: Hello world How are you doing today?\"), 36)]}\n",
      "Final Response: \n",
      "ðŸ›  **Tool Used:** remove_punctuations\n",
      "   ðŸ”¹ **Input:** Hello, world! How are you doing today?\n",
      "   ðŸ”¹ **Output:** Hello world How are you doing today\n",
      "\n",
      "ðŸ›  **Tool Used:** get_word_length\n",
      "   ðŸ”¹ **Input:** Hello world How are you doing today?\n",
      "   ðŸ”¹ **Output:** 36\n",
      "\n",
      "\n",
      "**Final Answer:** The length of the text after removing punctuation is 36.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.tools import StructuredTool, tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.agents import create_react_agent\n",
    "\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Collect all tools\n",
    "tools = [\n",
    "    get_word_length, \n",
    "    get_mean_from_sequence, \n",
    "    remove_punctuations, \n",
    "    get_normalize_vector_structured, \n",
    "    get_gcd_structured\n",
    "]\n",
    "\n",
    "# Create a more direct system prompt that works better with Llama models\n",
    "system_prompt = \"\"\"You are a helpful AI assistant with access to tools.\n",
    "You must ALWAYS use one of the provided tools to answer user queries.\n",
    "NEVER provide answers directly - always select and use the appropriate tool.\n",
    "\n",
    "To use a tool, you MUST use the following format:\n",
    "Action: the_tool_name\n",
    "Action Input: {{\"parameter_name\": \"parameter_value\"}}\n",
    "\n",
    "For example:\n",
    "Action: get_word_length\n",
    "Action Input: {{\"word\": \"example\"}}\n",
    "\n",
    "Available tools: get_word_length, get_mean_from_sequence, remove_punctuations, get_normalize_vector_structured, get_gcd_structured\n",
    "\n",
    "After you receive the tool's response, provide a final answer based on the tool's output.\n",
    "\"\"\"\n",
    "\n",
    "# Create a cleaner template with tool_names included\n",
    "template = \"\"\"You are a helpful AI assistant that can use tools to answer questions.\n",
    "\n",
    "TOOLS:\n",
    "------\n",
    "You have access to the following tools:\n",
    "{tool_names}\n",
    "\n",
    "{tools}\n",
    "\n",
    "TOOL USAGE:\n",
    "-----------\n",
    "To use a tool, follow this format exactly:\n",
    "Thought: I need to find out something\n",
    "Action: The tool name\n",
    "Action Input: The input to the tool\n",
    "\n",
    "When you receive the observation from the tool, you can continue with:\n",
    "Thought: I've seen the result\n",
    "Action: Another tool if needed\n",
    "Action Input: Another input\n",
    "\n",
    "When you're ready to give the final answer:\n",
    "Thought: I know the answer\n",
    "Final Answer: Your final answer here\n",
    "\n",
    "RULES:\n",
    "------\n",
    "- ALWAYS use a tool before giving a final answer\n",
    "- NEVER try to answer directly without using a tool\n",
    "- FORMAT your responses exactly as shown above\n",
    "- NEVER include both Action and Final Answer in the same step\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\", \"tools\", \"tool_names\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Connect to Ollama with lower temperature for more consistent output\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0.1,  # Lower temperature for more consistent outputs\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Create the agent using OpenAI functions format which works better with Llama models\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the agent executor with more iterations and better error handling\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=3,  # Reduce to simplify debugging\n",
    "    early_stopping_method=\"force\",\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "def run_agent(query, chat_history=None):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    try:\n",
    "        # Run the agent\n",
    "        result = agent_executor.invoke({\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        print(f\"Tools Available: {[tool.name for tool in tools]}\")\n",
    "\n",
    "        print(\"\\nRaw result:\", result)  # Debugging output\n",
    "\n",
    "        # Extract tool usage information\n",
    "        tool_usage_details = \"\"\n",
    "        if \"intermediate_steps\" in result:\n",
    "            for step in result[\"intermediate_steps\"]:\n",
    "                if isinstance(step, tuple) and len(step) == 2:\n",
    "                    tool_name = step[0].tool\n",
    "                    tool_input = step[0].tool_input\n",
    "                    tool_output = step[1]\n",
    "                    tool_usage_details += f\"\\nðŸ›  **Tool Used:** {tool_name}\\n   ðŸ”¹ **Input:** {tool_input}\\n   ðŸ”¹ **Output:** {tool_output}\\n\"\n",
    "\n",
    "        # Extract and clean output\n",
    "        output = result.get(\"output\", str(result)).strip()\n",
    "\n",
    "        # Append tool usage details to output\n",
    "        if tool_usage_details:\n",
    "            output = tool_usage_details + \"\\n\\n**Final Answer:** \" + output\n",
    "\n",
    "        # Prevent redundant messages in chat history\n",
    "        if not chat_history or chat_history[-1].content != output:\n",
    "            chat_history.append(HumanMessage(content=query))\n",
    "            chat_history.append(AIMessage(content=output))\n",
    "\n",
    "        return output, chat_history\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error executing agent: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return error_message, chat_history\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    chat_history = []\n",
    "    \n",
    "    # Example queries to test the agent\n",
    "    queries = [\n",
    "        \"What is the length of the word 'incomprehensibility'?\",\n",
    "        \"What is the mean of these numbers: 10,15,20,25,30?\",\n",
    "        \"What is the GCD of 48 and 18?\",\n",
    "        \"Can you normalize this vector: [3, 4]?\",\n",
    "        \"Remove the punctuation from this sentence: Hello, world! How are you doing today?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n\\nQuery: {query}\")\n",
    "        response, chat_history = run_agent(query, chat_history)\n",
    "        print(f\"Final Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tools directly:\n",
      "get_word_length('incomprehensibility'): 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/0x9ylhq57vq55_ssc_tyqhc00000gn/T/ipykernel_6035/3054406739.py:4: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(f\"get_word_length('incomprehensibility'): {get_word_length('incomprehensibility')}\")\n"
     ]
    }
   ],
   "source": [
    "# Add a quick debug function to test each tool directly\n",
    "def test_tools():\n",
    "    print(\"Testing tools directly:\")\n",
    "    print(f\"get_word_length('incomprehensibility'): {get_word_length('incomprehensibility')}\")\n",
    "    # Test other tools similarly\n",
    "\n",
    "test_tools()  # Call this before running the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
